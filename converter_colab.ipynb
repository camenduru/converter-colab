{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/converter-colab/blob/main/converter_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-yAt44bHJ2FA"
      },
      "outputs": [],
      "source": [
        "#@title ‚ôª\n",
        "!pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "!pip install -q gradio==3.9 jax[cpu]==0.4.4 flax==0.6.6 diffusers==0.13.1 accelerate==0.16.0 transformers==4.26.1 huggingface-hub==0.11.0 torch==1.13.1 safetensors==0.2.8 gdown==4.6.4 pytorch_lightning ftfy OmegaConf -U\n",
        "\n",
        "import os, gdown, gc\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from diffusers import FlaxStableDiffusionPipeline, StableDiffusionPipeline\n",
        "import torch\n",
        "from safetensors.torch import save_file, load_file\n",
        "from huggingface_hub import model_info, create_repo, create_branch, upload_folder\n",
        "from huggingface_hub.utils import RepositoryNotFoundError, RevisionNotFoundError\n",
        "\n",
        "def download_ckpt(ckpt_url):\n",
        "    if \"drive.google.com\" in ckpt_url:\n",
        "        gdown.download(url=ckpt_url, output=\"model.ckpt\", quiet=False, fuzzy=True)\n",
        "    else:\n",
        "        os.system(f\"wget {ckpt_url} -O model.ckpt\")\n",
        "    return \"download ckpt done!\"\n",
        "\n",
        "def download_vae(vae_url):\n",
        "    if \"drive.google.com\" in vae_url:\n",
        "        gdown.download(url=vae_url, output=\"vae.ckpt\", quiet=False, fuzzy=True)\n",
        "    else:\n",
        "        os.system(f\"wget {vae_url} -O vae.ckpt\")\n",
        "    return \"download vae done!\"\n",
        "\n",
        "def to_pt():\n",
        "    os.system(\"wget -q https://raw.githubusercontent.com/huggingface/diffusers/v0.13.1/scripts/convert_original_stable_diffusion_to_diffusers.py\")\n",
        "    os.system(f\"python3 convert_original_stable_diffusion_to_diffusers.py --checkpoint_path model.ckpt --dump_path pt\")\n",
        "    return \"convert to pt done!\"\n",
        "\n",
        "def from_safetensors_to_pt():\n",
        "    os.system(\"wget -q https://raw.githubusercontent.com/huggingface/diffusers/v0.13.1/scripts/convert_original_stable_diffusion_to_diffusers.py\")\n",
        "    os.system(f\"python3 convert_original_stable_diffusion_to_diffusers.py --from_safetensors --checkpoint_path model.safetensors --dump_path pt\")\n",
        "    return \"convert to pt done!\"\n",
        "\n",
        "def from_ckpt_to_safetensors():\n",
        "    os.system(\"wget -q https://raw.githubusercontent.com/huggingface/diffusers/v0.13.1/scripts/convert_original_stable_diffusion_to_diffusers.py\")\n",
        "    os.system(f\"python3 convert_original_stable_diffusion_to_diffusers.py --checkpoint_path model.ckpt --to_safetensors --dump_path safetensors\")\n",
        "    return \"convert to safetensors done!\"\n",
        "\n",
        "def from_safetensors_to_safetensors():\n",
        "    os.system(\"wget -q https://raw.githubusercontent.com/huggingface/diffusers/v0.13.1/scripts/convert_original_stable_diffusion_to_diffusers.py\")\n",
        "    os.system(f\"python3 convert_original_stable_diffusion_to_diffusers.py --from_safetensors --checkpoint_path model.safetensors --to_safetensors --dump_path safetensors\")\n",
        "    return \"convert to safetensors done!\"\n",
        "\n",
        "def from_safetensors_to_emaonly(safetensors_emaonly_name):\n",
        "    os.system(\"mkdir safetensors\")\n",
        "    tensors = load_file(\"model.safetensors\")\n",
        "    filtered_only_ema = {k: v for k, v in tensors.items() if not k.startswith(\"model.\")}\n",
        "    save_file(filtered_only_ema, f\"safetensors/{safetensors_emaonly_name}-emaonly.safetensors\")\n",
        "    return \"convert to safetensors emaonly done!\"\n",
        "\n",
        "def swap_ckpt_vae(ckpt_name):\n",
        "    os.system(\"mkdir ckpt\")\n",
        "    model = torch.load(\"model.ckpt\", map_location=\"cpu\")\n",
        "    if \"state_dict\" in model:\n",
        "      sd = model[\"state_dict\"]\n",
        "    else:\n",
        "      sd = model\n",
        "    full_model = False\n",
        "    vae_model = torch.load(\"vae.ckpt\", map_location=\"cpu\")\n",
        "    vae_sd = vae_model['state_dict']\n",
        "    for vae_key in vae_sd:\n",
        "      if vae_key.startswith(\"first_stage_model.\"):\n",
        "        full_model = True\n",
        "        break\n",
        "    for vae_key in vae_sd:\n",
        "      sd_key = vae_key\n",
        "      if full_model:\n",
        "        if not sd_key.startswith(\"first_stage_model.\"):\n",
        "          continue\n",
        "      else:\n",
        "        if sd_key not in sd:\n",
        "          sd_key = \"first_stage_model.\" + sd_key\n",
        "      if sd_key not in sd:\n",
        "        continue\n",
        "      sd[sd_key] = vae_sd[vae_key]\n",
        "    torch.save(model, f\"ckpt/{ckpt_name}-vae-swapped.ckpt\")\n",
        "    del model\n",
        "    del vae_model\n",
        "    del sd\n",
        "    del vae_sd\n",
        "    gc.collect()\n",
        "    return \"swap ckpt vae done!\"\n",
        "\n",
        "def push_pt(model_to, token, branch):\n",
        "    try:\n",
        "        repo_exists = True\n",
        "        r_info = model_info(model_to, token=token)\n",
        "    except RepositoryNotFoundError:\n",
        "        repo_exists = False\n",
        "    finally:\n",
        "        if repo_exists:\n",
        "            print(r_info)\n",
        "        else:\n",
        "            create_repo(model_to, private=True, token=token)\n",
        "    try:\n",
        "        branch_exists = True\n",
        "        b_info = model_info(model_to, revision=branch, token=token)\n",
        "    except RevisionNotFoundError:\n",
        "        branch_exists = False\n",
        "    finally:\n",
        "        if branch_exists:\n",
        "            print(b_info)\n",
        "        else:\n",
        "            create_branch(model_to, branch=branch, token=token)\n",
        "    upload_folder(folder_path=\"pt\", path_in_repo=\"\", revision=branch, repo_id=model_to, commit_message=f\"pt - camenduru/converter\", token=token)\n",
        "    return \"push pt done!\"\n",
        "    \n",
        "def delete_pt():\n",
        "    os.system(f\"rm -rf pt\")\n",
        "    return \"delete pt done!\"\n",
        "    \n",
        "def clone_pt(model_url):\n",
        "    os.system(\"git lfs install\")\n",
        "    os.system(f\"git clone https://huggingface.co/{model_url} pt\")\n",
        "    return \"clone pt done!\"\n",
        "    \n",
        "def pt_to_flax():\n",
        "    pipe, params = FlaxStableDiffusionPipeline.from_pretrained(\"pt\", from_pt=True)\n",
        "    pipe.save_pretrained(\"flax\", params=params)\n",
        "    return \"convert to flax done!\"\n",
        "\n",
        "def push_flax(model_to, token, branch):\n",
        "    try:\n",
        "        repo_exists = True\n",
        "        r_info = model_info(model_to, token=token)\n",
        "    except RepositoryNotFoundError:\n",
        "        repo_exists = False\n",
        "    finally:\n",
        "        if repo_exists:\n",
        "            print(r_info)\n",
        "        else:\n",
        "            create_repo(model_to, private=True, token=token)\n",
        "    try:\n",
        "        branch_exists = True\n",
        "        b_info = model_info(model_to, revision=branch, token=token)\n",
        "    except RevisionNotFoundError:\n",
        "        branch_exists = False\n",
        "    finally:\n",
        "        if branch_exists:\n",
        "            print(b_info)\n",
        "        else:\n",
        "            create_branch(model_to, branch=branch, token=token)\n",
        "    upload_folder(folder_path=\"flax\", path_in_repo=\"\", revision=branch, repo_id=model_to, commit_message=f\"flax - camenduru/converter\", token=token)\n",
        "    return \"push flax done!\"\n",
        "\n",
        "def delete_flax():\n",
        "    os.system(f\"rm -rf flax\")\n",
        "    return \"delete flax done!\"\n",
        "    \n",
        "def flax_to_pt():\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\"flax\", from_flax=True, safety_checker=None)\n",
        "    pipe.save_pretrained(\"pt\")\n",
        "    return \"convert to pt done!\"\n",
        "    \n",
        "def clone_flax(model_url):\n",
        "    os.system(\"git lfs install\")\n",
        "    os.system(f\"git clone https://huggingface.co/{model_url} flax\")\n",
        "    return \"clone flax done!\"\n",
        "    \n",
        "def to_ckpt(ckpt_name):\n",
        "    os.system(\"wget -q https://raw.githubusercontent.com/huggingface/diffusers/v0.13.1/scripts/convert_diffusers_to_original_stable_diffusion.py\")\n",
        "    os.system(\"mkdir ckpt\")\n",
        "    os.system(f\"python3 convert_diffusers_to_original_stable_diffusion.py --model_path pt --checkpoint_path ckpt/{ckpt_name}.ckpt\")\n",
        "    return \"convert to ckpt done!\"\n",
        "\n",
        "def push_ckpt(model_to, token, branch):\n",
        "    try:\n",
        "        repo_exists = True\n",
        "        r_info = model_info(model_to, token=token)\n",
        "    except RepositoryNotFoundError:\n",
        "        repo_exists = False\n",
        "    finally:\n",
        "        if repo_exists:\n",
        "            print(r_info)\n",
        "        else:\n",
        "            create_repo(model_to, private=True, token=token)\n",
        "    try:\n",
        "        branch_exists = True\n",
        "        b_info = model_info(model_to, revision=branch, token=token)\n",
        "    except RevisionNotFoundError:\n",
        "        branch_exists = False\n",
        "    finally:\n",
        "        if branch_exists:\n",
        "            print(b_info)\n",
        "        else:\n",
        "            create_branch(model_to, branch=branch, token=token)    \n",
        "    upload_folder(folder_path=\"ckpt\", path_in_repo=\"\", revision=branch, repo_id=model_to, commit_message=f\"ckpt - camenduru/converter\", token=token)\n",
        "    return \"push ckpt done!\"\n",
        "    \n",
        "def delete_ckpt():\n",
        "    os.system(f\"rm -rf ckpt\")\n",
        "    return \"delete ckpt done!\"\n",
        "\n",
        "def to_safetensors(safetensors_name):\n",
        "    os.system(\"mkdir safetensors\")\n",
        "    weights = torch.load(\"model.ckpt\", map_location=\"cpu\")\n",
        "    if \"state_dict\" in weights:\n",
        "        weights = weights[\"state_dict\"]\n",
        "    save_file(weights, f\"safetensors/{safetensors_name}.safetensors\")\n",
        "    return \"convert to safetensors done!\"\n",
        "\n",
        "def push_safetensors(model_to, token, branch):\n",
        "    try:\n",
        "        repo_exists = True\n",
        "        r_info = model_info(model_to, token=token)\n",
        "    except RepositoryNotFoundError:\n",
        "        repo_exists = False\n",
        "    finally:\n",
        "        if repo_exists:\n",
        "            print(r_info)\n",
        "        else:\n",
        "            create_repo(model_to, private=True, token=token)\n",
        "    try:\n",
        "        branch_exists = True\n",
        "        b_info = model_info(model_to, revision=branch, token=token)\n",
        "    except RevisionNotFoundError:\n",
        "        branch_exists = False\n",
        "    finally:\n",
        "        if branch_exists:\n",
        "            print(b_info)\n",
        "        else:\n",
        "            create_branch(model_to, branch=branch, token=token)\n",
        "    upload_folder(folder_path=\"safetensors\", path_in_repo=\"\", revision=branch, repo_id=model_to, commit_message=f\"safetensors - camenduru/converter\", token=token)\n",
        "    return \"push safetensors done!\"\n",
        "\n",
        "def delete_safetensors():\n",
        "    os.system(f\"rm -rf safetensors\")\n",
        "    return \"delete safetensors done!\"\n",
        "\n",
        "def download_safetensors(safetensors_url):\n",
        "    if \"drive.google.com\" in safetensors_url:\n",
        "        gdown.download(url=ckpt_url, output=\"model.safetensors\", quiet=False, fuzzy=True)\n",
        "    else:\n",
        "        os.system(f\"wget {safetensors_url} -O model.safetensors\")\n",
        "    return \"download safetensors done!\"\n",
        "\n",
        "def from_safetensors_to_ckpt(ckpt_name):\n",
        "    weights = load_file(\"model.safetensors\", device=\"cpu\")\n",
        "    os.system(\"mkdir ckpt\")\n",
        "    torch.save(weights, f\"ckpt/{ckpt_name}.ckpt\")\n",
        "    return \"convert to ckpt done!\"\n",
        "\n",
        "def delete_all():\n",
        "    delete_pt()\n",
        "    delete_flax()\n",
        "    delete_ckpt()\n",
        "    delete_safetensors()\n",
        "    return \"delete all done!\"\n",
        "    \n",
        "block = gr.Blocks()\n",
        "\n",
        "with block:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ## üö® Please first click delete all button üö® Thanks to ü§ó ‚ù§ Now with CPU Upgrade! üéâ <a style=\"display:inline-block\" href=\"https://github.com/camenduru/converter-colab\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"margin-bottom: 0px; margin-top: 0px;\"></a>\t\n",
        "    üê£ Please follow me for new updates <a href=\"https://twitter.com/camenduru\">https://twitter.com/camenduru</a>\n",
        "    \"\"\")\n",
        "    with gr.Row().style(equal_height=True):\n",
        "        btn_delete_all = gr.Button(\"Delete ALL\")\n",
        "        out_all = gr.Textbox(show_label=False)\n",
        "        btn_delete_all.click(delete_all, outputs=out_all)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### ckpt to diffusers pytorch\n",
        "    ckpt_url = <small>https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.ckpt or https://drive.google.com/file/d/file-id/view?usp=share_link or \"https://civitai.com/api/download/models/5616?type=Model&format=PickleTensor\"</small><br />\n",
        "    pt_model_to = camenduru/openjourney <br />\n",
        "    branch = main <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_ckpt_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ckpt_url\")\n",
        "                text_pt_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"pt_model_to\")\n",
        "                text_pt_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"pt_branch\")\n",
        "                text_pt_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_pt = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_download_ckpt = gr.Button(\"Download CKPT\")\n",
        "                btn_to_pt = gr.Button(\"Convert to Diffusers PT\")\n",
        "                btn_push_pt = gr.Button(\"Push Diffusers PT to ü§ó\")\n",
        "                btn_delete_pt = gr.Button(\"Delete Diffusers PT\")\n",
        "        btn_download_ckpt.click(download_ckpt, inputs=[text_ckpt_url], outputs=out_pt)\n",
        "        btn_to_pt.click(to_pt, outputs=out_pt)\n",
        "        btn_push_pt.click(push_pt, inputs=[text_pt_model_to, text_pt_token, text_pt_branch], outputs=out_pt)\n",
        "        btn_delete_pt.click(delete_pt, outputs=out_pt)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### ckpt to diffusers safetensors\n",
        "    ckpt_url = <small>https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.ckpt or https://drive.google.com/file/d/file-id/view?usp=share_link or \"https://civitai.com/api/download/models/5616?type=Model&format=PickleTensor\"</small><br />\n",
        "    safetensors_pt_model_to = camenduru/openjourney <br />\n",
        "    branch = main <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_ckpt_to_safetensors_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ckpt_url\")\n",
        "                text_ckpt_to_safetensors_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"safetensors_pt_model_to\")\n",
        "                text_ckpt_to_safetensors_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"safetensors_branch\")\n",
        "                text_ckpt_to_safetensors_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_ckpt_to_safetensors = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_download_ckpt_to_safetensors = gr.Button(\"Download CKPT\")\n",
        "                btn_ckpt_to_safetensors = gr.Button(\"Convert to Diffusers Safetensors\")\n",
        "                btn_push_ckpt_to_safetensors = gr.Button(\"Push Diffusers Safetensors to ü§ó\")\n",
        "                btn_delete_ckpt_to_safetensors = gr.Button(\"Delete Diffusers Safetensors\")\n",
        "        btn_download_ckpt_to_safetensors.click(download_ckpt, inputs=[text_ckpt_to_safetensors_url], outputs=out_ckpt_to_safetensors)\n",
        "        btn_ckpt_to_safetensors.click(from_ckpt_to_safetensors, outputs=out_ckpt_to_safetensors)\n",
        "        btn_push_ckpt_to_safetensors.click(push_safetensors, inputs=[text_ckpt_to_safetensors_model_to, text_ckpt_to_safetensors_token, text_ckpt_to_safetensors_branch], outputs=out_ckpt_to_safetensors)\n",
        "        btn_delete_ckpt_to_safetensors.click(delete_safetensors, outputs=out_ckpt_to_safetensors)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### safetensors to diffusers pytorch\n",
        "    safetensors_url = <small>https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.safetensors or https://drive.google.com/file/d/file-id/view?usp=share_link or \"https://civitai.com/api/download/models/5616?type=Model&format=SafeTensor\"</small><br />\n",
        "    pt_model_to = camenduru/openjourney <br />\n",
        "    branch = main <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_safetensors_to_pt_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"safetensors_url\")\n",
        "                text_safetensors_to_pt_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"pt_model_to\")\n",
        "                text_safetensors_to_pt_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"pt_branch\")\n",
        "                text_safetensors_to_pt_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_safetensors_to_pt = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_download_safetensors_to_pt = gr.Button(\"Download Safetensors\")\n",
        "                btn_safetensors_to_pt = gr.Button(\"Convert to Diffusers PT\")\n",
        "                btn_push_safetensors_to_pt = gr.Button(\"Push Diffusers PT to ü§ó\")\n",
        "                btn_delete_safetensors_to_pt = gr.Button(\"Delete Diffusers PT\")\n",
        "        btn_download_safetensors_to_pt.click(download_safetensors, inputs=[text_safetensors_to_pt_url], outputs=out_safetensors_to_pt)\n",
        "        btn_safetensors_to_pt.click(from_safetensors_to_pt, outputs=out_safetensors_to_pt)\n",
        "        btn_push_safetensors_to_pt.click(push_pt, inputs=[text_safetensors_to_pt_model_to, text_safetensors_to_pt_token, text_safetensors_to_pt_branch], outputs=out_safetensors_to_pt)\n",
        "        btn_delete_safetensors_to_pt.click(delete_pt, outputs=out_safetensors_to_pt)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### safetensors to diffusers safetensors\n",
        "    safetensors_url = <small>https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.ckpt or https://drive.google.com/file/d/file-id/view?usp=share_link or \"https://civitai.com/api/download/models/5616?type=Model&format=SafeTensor\"</small><br />\n",
        "    safetensors_model_to = camenduru/openjourney <br />\n",
        "    branch = main <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_safetensors_to_safetensors_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"safetensors_url\")\n",
        "                text_safetensors_to_safetensors_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"safetensors_model_to\")\n",
        "                text_safetensors_to_safetensors_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"pt_branch\")\n",
        "                text_safetensors_to_safetensors_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_safetensors_to_safetensors = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_download_safetensors_to_safetensors = gr.Button(\"Download Safetensors\")\n",
        "                btn_safetensors_to_safetensors = gr.Button(\"Convert to Diffusers Safetensors\")\n",
        "                btn_push_safetensors_to_safetensors = gr.Button(\"Push Diffusers Safetensors to ü§ó\")\n",
        "                btn_delete_safetensors_to_safetensors = gr.Button(\"Delete Diffusers Safetensors\")\n",
        "        btn_download_safetensors_to_safetensors.click(download_safetensors, inputs=[text_safetensors_to_safetensors_url], outputs=out_safetensors_to_safetensors)\n",
        "        btn_safetensors_to_safetensors.click(from_safetensors_to_safetensors, outputs=out_safetensors_to_safetensors)\n",
        "        btn_push_safetensors_to_safetensors.click(push_safetensors, inputs=[text_safetensors_to_safetensors_model_to, text_safetensors_to_safetensors_token, text_safetensors_to_safetensors_branch], outputs=out_safetensors_to_safetensors)\n",
        "        btn_delete_safetensors_to_safetensors.click(delete_safetensors, outputs=out_safetensors_to_safetensors)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### diffusers pytorch to diffusers flax <br />\n",
        "    pt_model_from = dreamlike-art/dreamlike-diffusion-1.0 <br />\n",
        "    flax_model_to = camenduru/dreamlike-diffusion-1.0 <br />\n",
        "    branch = flax <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write <br />\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_pt_model_from = gr.Textbox(show_label=False, max_lines=1, placeholder=\"pt_model_from\")\n",
        "                text_flax_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"flax_model_to\")\n",
        "                text_flax_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"flax_branch\")\n",
        "                text_flax_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_flax = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_clone_pt = gr.Button(\"Clone Diffusers PT from ü§ó\")\n",
        "                btn_to_flax = gr.Button(\"Convert to Diffusers Flax\")\n",
        "                btn_push_flax = gr.Button(\"Push Diffusers Flax to ü§ó\")\n",
        "                btn_delete_flax = gr.Button(\"Delete Diffusers Flax\")\n",
        "        btn_clone_pt.click(clone_pt, inputs=[text_pt_model_from], outputs=out_flax)\n",
        "        btn_to_flax.click(pt_to_flax, outputs=out_flax)\n",
        "        btn_push_flax.click(push_flax, inputs=[text_flax_model_to, text_flax_token, text_flax_branch], outputs=out_flax)\n",
        "        btn_delete_flax.click(delete_flax, outputs=out_flax)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### diffusers flax to diffusers pytorch <br />\n",
        "    flax_model_from = flax/mo-di-diffusion <br />\n",
        "    pt_model_to =  camenduru/mo-di-diffusion <br />\n",
        "    branch = pt <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write <br />\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_flax_model_from = gr.Textbox(show_label=False, max_lines=1, placeholder=\"flax_model_from\")\n",
        "                text_pt_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"pt_model_to\")\n",
        "                text_pt_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"pt_branch\")\n",
        "                text_pt_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_pt = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_clone_flax = gr.Button(\"Clone Diffusers Flax from ü§ó\")\n",
        "                btn_to_pt = gr.Button(\"Convert to Diffusers PT\")\n",
        "                btn_push_pt = gr.Button(\"Push Diffusers PT to ü§ó\")\n",
        "                btn_delete_pt = gr.Button(\"Delete Diffusers PT\")\n",
        "        btn_clone_flax.click(clone_flax, inputs=[text_flax_model_from], outputs=out_pt)\n",
        "        btn_to_pt.click(flax_to_pt, outputs=out_pt)\n",
        "        btn_push_pt.click(push_pt, inputs=[text_pt_model_to, text_pt_token, text_pt_branch], outputs=out_pt)\n",
        "        btn_delete_pt.click(delete_pt, outputs=out_pt)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### diffusers pytorch to ckpt\n",
        "    pt_model_from = prompthero/openjourney <br />\n",
        "    ckpt_name = openjourney <br />\n",
        "    ckpt_model_to = camenduru/openjourney <br />\n",
        "    branch = ckpt <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_pt_model_from = gr.Textbox(show_label=False, max_lines=1, placeholder=\"pt_model_from\")\n",
        "                text_ckpt_name = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ckpt_name\")\n",
        "                text_ckpt_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ckpt_model_to\")\n",
        "                text_ckpt_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"ckpt_branch\")\n",
        "                text_ckpt_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_ckpt = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_clone_pt = gr.Button(\"Clone Diffusers PT from ü§ó\")\n",
        "                btn_to_ckpt = gr.Button(\"Convert to CKPT\")\n",
        "                btn_push_ckpt = gr.Button(\"Push CKPT to ü§ó\")\n",
        "                btn_delete_ckpt = gr.Button(\"Delete CKPT\")\n",
        "        btn_clone_pt.click(clone_pt, inputs=[text_pt_model_from], outputs=out_ckpt)\n",
        "        btn_to_ckpt.click(to_ckpt, inputs=[text_ckpt_name], outputs=out_ckpt)\n",
        "        btn_push_ckpt.click(push_ckpt, inputs=[text_ckpt_model_to, text_ckpt_token, text_ckpt_branch], outputs=out_ckpt)\n",
        "        btn_delete_ckpt.click(delete_ckpt, outputs=out_ckpt)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### ckpt to safetensors <br />\n",
        "    ckpt_url = <small>https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.ckpt or https://drive.google.com/file/d/file-id/view?usp=share_link or \"https://civitai.com/api/download/models/5616?type=Model&format=PickleTensor\"</small><br />\n",
        "    safetensors_name = openjourney <br />\n",
        "    safetensors_model_to = camenduru/openjourney <br />\n",
        "    branch = safetensors <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write <br />\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_ckpt_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ckpt_url\")\n",
        "                text_safetensors_name = gr.Textbox(show_label=False, max_lines=1, placeholder=\"safetensors_name\")\n",
        "                text_safetensors_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"safetensors_model_to\")\n",
        "                text_safetensors_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"safetensors_branch\")\n",
        "                text_safetensors_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_safetensors = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_download_ckpt = gr.Button(\"Download CKPT\")\n",
        "                btn_to_safetensors = gr.Button(\"Convert to Safetensors\")\n",
        "                btn_push_safetensors = gr.Button(\"Push Safetensors to ü§ó\")\n",
        "                btn_delete_safetensors = gr.Button(\"Delete Safetensors\")\n",
        "        btn_download_ckpt.click(download_ckpt, inputs=[text_ckpt_url], outputs=out_safetensors)\n",
        "        btn_to_safetensors.click(to_safetensors, inputs=[text_safetensors_name], outputs=out_safetensors)\n",
        "        btn_push_safetensors.click(push_safetensors, inputs=[text_safetensors_model_to, text_safetensors_token, text_safetensors_branch], outputs=out_safetensors)\n",
        "        btn_delete_safetensors.click(delete_safetensors, outputs=out_safetensors)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### safetensors to ckpt <br />\n",
        "    safetensors_url = <small>https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.safetensors or https://drive.google.com/file/d/file-id/view?usp=share_link or \"https://civitai.com/api/download/models/5616?type=Model&format=SafeTensor\"</small><br />\n",
        "    ckpt_name = openjourney <br />\n",
        "    ckpt_model_to = camenduru/openjourney <br />\n",
        "    branch = ckpt <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write <br />\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_safetensors_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"safetensors_url\")\n",
        "                text_safetensors_to_ckpt_name = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ckpt_name\")\n",
        "                text_safetensors_to_ckpt_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ckpt_model_to\")\n",
        "                text_safetensors_to_ckpt_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"ckpt_branch\")\n",
        "                text_safetensors_to_ckpt_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_safetensors_to_ckpt = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_download_safetensors = gr.Button(\"Download Safetensors\")\n",
        "                btn_safetensors_to_ckpt = gr.Button(\"Convert to CKPT\")\n",
        "                btn_push_safetensors_to_ckpt = gr.Button(\"Push CKPT to ü§ó\")\n",
        "                btn_delete_safetensors_ckpt = gr.Button(\"Delete CKPT\")\n",
        "        btn_download_safetensors.click(download_safetensors, inputs=[text_safetensors_url], outputs=out_safetensors_to_ckpt)\n",
        "        btn_safetensors_to_ckpt.click(from_safetensors_to_ckpt, inputs=[text_safetensors_to_ckpt_name], outputs=out_safetensors_to_ckpt)\n",
        "        btn_push_safetensors_to_ckpt.click(push_ckpt, inputs=[text_safetensors_to_ckpt_model_to, text_safetensors_to_ckpt_token, text_safetensors_to_ckpt_branch], outputs=out_safetensors_to_ckpt)\n",
        "        btn_delete_safetensors_ckpt.click(delete_ckpt, outputs=out_safetensors_to_ckpt)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### safetensors to safetensors emaonly <br />\n",
        "    safetensors_url = <small>https://huggingface.co/ckpt/anything-v3.0/resolve/main/Anything-V3.0.safetensors or https://drive.google.com/file/d/file-id/view?usp=share_link or \"https://civitai.com/api/download/models/4298?type=Model&format=SafeTensor\"</small><br />\n",
        "    emaonly_name = Anything-V3.0 <br />\n",
        "    emaonly_model_to = camenduru/Anything-V3.0 <br />\n",
        "    branch = safetensors <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write <br />\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_safetensors_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"safetensors_url\")\n",
        "                text_safetensors_to_emaonly_name = gr.Textbox(show_label=False, max_lines=1, placeholder=\"emaonly_name\")\n",
        "                text_safetensors_to_emaonly_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"emaonly_model_to\")\n",
        "                text_safetensors_to_emaonly_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"emaonly_branch\")\n",
        "                text_safetensors_to_emaonly_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_safetensors_to_emaonly = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_download_safetensors = gr.Button(\"Download Safetensors\")\n",
        "                btn_safetensors_to_emaonly = gr.Button(\"Convert to EMA Safetensors\")\n",
        "                btn_push_safetensors_to_emaonly = gr.Button(\"Push EMA Safetensors to ü§ó\")\n",
        "                btn_delete_safetensors_emaonly = gr.Button(\"Delete EMA Safetensors\")\n",
        "        btn_download_safetensors.click(download_safetensors, inputs=[text_safetensors_url], outputs=out_safetensors_to_emaonly)\n",
        "        btn_safetensors_to_emaonly.click(from_safetensors_to_emaonly, inputs=[text_safetensors_to_emaonly_name], outputs=out_safetensors_to_emaonly)\n",
        "        btn_push_safetensors_to_emaonly.click(push_safetensors, inputs=[text_safetensors_to_emaonly_model_to, text_safetensors_to_emaonly_token, text_safetensors_to_emaonly_branch], outputs=out_safetensors_to_emaonly)\n",
        "        btn_delete_safetensors_emaonly.click(delete_safetensors, outputs=out_safetensors_to_emaonly)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### swap ckpt vae <br />\n",
        "    ckpt_url = <small>https://huggingface.co/ckpt/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt or https://drive.google.com/file/d/file-id/view?usp=share_link or \"https://civitai.com/api/download/models/75?type=Model&format=PickleTensor\"</small><br />\n",
        "    vae_url = <small>https://huggingface.co/ckpt/anything-v3.0/resolve/main/Anything-V3.0.vae.pt or https://drive.google.com/file/d/file-id/view?usp=share_link or \"https://civitai.com/api/download/models/5809?type=VAE&format=Other\"</small><br />\n",
        "    swaped_ckpt_name = Anything-V3.0 <br />\n",
        "    swaped_ckpt_model_to = camenduru/Anything-V3.0 <br />\n",
        "    swaped_ckpt_branch = ckpt <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write <br />\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_ckpt_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ckpt_url\")\n",
        "                text_vae_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"vae_url\")\n",
        "                text_swap_ckpt_name = gr.Textbox(show_label=False, max_lines=1, placeholder=\"swaped_ckpt_name\")\n",
        "                text_swap_ckpt_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"swaped_ckpt_model_to\")\n",
        "                text_swap_ckpt_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"swaped_ckpt_branch\")\n",
        "                text_swap_ckpt_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ü§ó token\")\n",
        "                out_swap_ckpt = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_download_ckpt = gr.Button(\"Download CKPT\")\n",
        "                btn_download_vae = gr.Button(\"Download VAE\")\n",
        "                btn_to_swap_ckpt = gr.Button(\"Swap CKPT VAE\")\n",
        "                btn_push_swap_ckpt = gr.Button(\"Push CKPT to ü§ó\")\n",
        "                btn_delete_swap_ckpt = gr.Button(\"Delete CKPT\")\n",
        "        btn_download_ckpt.click(download_ckpt, inputs=[text_ckpt_url], outputs=out_swap_ckpt)\n",
        "        btn_download_vae.click(download_vae, inputs=[text_vae_url], outputs=out_swap_ckpt)\n",
        "        btn_to_swap_ckpt.click(swap_ckpt_vae, inputs=[text_swap_ckpt_name], outputs=out_swap_ckpt)\n",
        "        btn_push_swap_ckpt.click(push_ckpt, inputs=[text_swap_ckpt_model_to, text_swap_ckpt_token, text_swap_ckpt_branch], outputs=out_swap_ckpt)\n",
        "        btn_delete_swap_ckpt.click(delete_ckpt, outputs=out_swap_ckpt)\n",
        "block.launch(share=True, inline=False, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
